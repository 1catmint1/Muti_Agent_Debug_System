"""
PythonFixer - Pythonä»£ç ä¿®å¤å™¨ï¼ˆæ”¯æŒ DebugBench é€»è¾‘å·®å¼‚é©±åŠ¨ + å½’ä¸€åŒ–ï¼‰
"""
import re
from typing import Dict, List, Any, Union

from .base_fixer import BaseFixer, FixResult, Language


class PythonFixer(BaseFixer):
    """Pythonä¸“ç”¨ä¿®å¤å™¨"""

    def __init__(self, llm_client=None, prompt_config: Dict[str, Any] = None):
        super().__init__(Language.PYTHON, llm_client)
        # [ä¿æŒä¸ CppFixer ä¸€è‡´çš„ prompt é…ç½®]
        self.prompt_conf = prompt_config or {
            "language": "zh",
            "style": "concise",
            "force_code_block_only": True
        }

    # =========================================================
    #  LLM è¾…åŠ©ï¼šé”™è¯¯ä»£ç  vs æ­£ç¡®ä»£ç  çš„é€»è¾‘å·®å¼‚åˆ†æ
    # =========================================================
    def _analyze_logic_diff_v2(self, buggy_code: str, reference_code: str) -> List[Dict[str, str]]:
        """
        ä½¿ç”¨ LLM æ¯”è¾ƒ Python é”™è¯¯ä»£ç  A ä¸æ­£ç¡®ä»£ç  Bï¼Œè‡ªåŠ¨ç”Ÿæˆã€Œé€»è¾‘å·®å¼‚æŠ¥å‘Šã€ã€‚

        âš ï¸ ä¸æ³„éœ² ground truthï¼ˆç¦æ­¢è¾“å‡ºæ­£ç¡®ä»£ç ï¼‰
        âš ï¸ åªè¾“å‡º JSON æ•°ç»„
        """
        if not self.llm_client:
            return [{"type": "NO_LLM", "message": "LLM å®¢æˆ·ç«¯æœªé…ç½®ï¼Œæ— æ³•åˆ†æé€»è¾‘å·®å¼‚"}]

        try:
            prompt = (
                "ä½ æ˜¯ä¸€å Python ç¨‹åºç»“æ„ä¸é€»è¾‘åˆ†æä¸“å®¶ã€‚\n"
                "ä¸‹é¢æ˜¯ä¸¤ä»½ä»£ç ï¼šA æ˜¯é”™è¯¯ç‰ˆæœ¬ï¼ŒB æ˜¯æ­£ç¡®ç‰ˆæœ¬ã€‚\n"
                "ä½ çš„ä»»åŠ¡ï¼š\n"
                "  1. æ¯”è¾ƒ A ä¸ B çš„é€»è¾‘è¡Œä¸ºå·®å¼‚ï¼ˆæµç¨‹ã€æ¡ä»¶ã€å¾ªç¯ã€è¾¹ç•Œã€é€’å½’ã€å˜é‡æ›´æ–°ï¼‰ã€‚\n"
                "  2. ä¸èƒ½è¾“å‡º B çš„ä»»ä½•ä»£ç ï¼Œä¸èƒ½æ³„éœ²æ­£ç¡®å®ç°å†…å®¹ã€‚\n"
                "  3. åªèƒ½ç”¨æ–‡å­—æè¿°å·®å¼‚ï¼Œæ¯æ¡å·®å¼‚ç”¨ JSON å¯¹è±¡è¡¨ç¤ºï¼Œä¾‹å¦‚ï¼š\n"
                "     {\"type\": \"MISSING_LOGIC\", \"message\": \"A ç¼ºå°‘å¤„ç†ç©ºåˆ—è¡¨çš„é€»è¾‘\"}\n"
                "æœ€ç»ˆè¾“å‡ºä¸€ä¸ª JSON æ•°ç»„ã€‚\n\n"
                "=== é”™è¯¯ä»£ç  A ===\n"
                f"{buggy_code}\n\n"
                "=== æ­£ç¡®ä»£ç  Bï¼ˆç¦æ­¢æ³„éœ²ï¼‰===\n"
                f"{reference_code}\n\n"
                "=== è¯·è¾“å‡º JSON æ•°ç»„ï¼ˆä¸èƒ½åŒ…å«ä»£ç ï¼‰ ==="
            )

            response = self.llm_client.chat(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=1500,
            )

            import json
            data = json.loads(response)
            if isinstance(data, list):
                return data

            return [{"type": "PARSE_FAIL", "message": "LLM è¾“å‡ºä¸æ˜¯ JSON æ•°ç»„"}]

        except Exception as e:
            return [{"type": "ANALYSIS_FAIL", "message": f"åˆ†æå¤±è´¥: {e}"}]

    # =========================================================
    #  è§„åˆ™ä¿®å¤éƒ¨åˆ†
    # =========================================================
    def apply_rule_fixes(self, file: Dict[str, Any], issues: List[Union[Dict, str]]) -> FixResult:
        """åº”ç”¨è§„åˆ™åŒ–ä¿®å¤ï¼ˆè½»é‡ï¼Œä¸»è¦å¤„ç† Py2 / æ ¼å¼ç±»é—®é¢˜ï¼‰"""
        filename = file.get("file", "")
        content = file.get("content", "")
        fixed_content = content
        fixed_count = 0

        print(f"[PythonFixer] å¼€å§‹è§„åˆ™ä¿®å¤: {filename}")
        print(f"[PythonFixer] å¾…ä¿®å¤é—®é¢˜æ•°: {len(issues)}")

        normalized_issues = self._normalize_issues(issues)

        if any(issue.get("rule_id") == "PY201" for issue in normalized_issues):
            new_content = re.sub(r'\bxrange\b', 'range', fixed_content)
            if new_content != fixed_content:
                fixed_content = new_content
                fixed_count += 1

        if any(issue.get("rule_id") == "PY203" for issue in normalized_issues):
            new_content = re.sub(r'\braw_input\b', 'input', fixed_content)
            if new_content != fixed_content:
                fixed_content = new_content
                fixed_count += 1

        if any("except" in str(issue).lower() and "," in str(issue) for issue in normalized_issues):
            pattern = r'except\s+(\w+)\s*,\s*(\w+)'
            new_content = re.sub(pattern, r'except \1 as \2', fixed_content)
            if new_content != fixed_content:
                fixed_content = new_content
                fixed_count += 1

        if any("print" in str(issue).lower() for issue in normalized_issues):
            pattern = r'print\s+"([^"]*)"'
            new_content = re.sub(pattern, r'print("\1")', fixed_content)
            if new_content != fixed_content:
                fixed_content = new_content
                fixed_count += 1

        fixed_content, additional_fixes = self._apply_common_fixes(fixed_content, normalized_issues)
        fixed_count += additional_fixes

        print(f"[PythonFixer] è§„åˆ™ä¿®å¤å®Œæˆ: ä¿®å¤äº† {fixed_count} å¤„é—®é¢˜")

        return FixResult(
            file=filename,
            language=self.language.value,
            original_content=content,
            fixed_content=fixed_content,
            fixed_count=fixed_count,
            method="rule",
            success=fixed_count > 0,
            error_message="" if fixed_count > 0 else "æ²¡æœ‰æ‰¾åˆ°å¯è‡ªåŠ¨ä¿®å¤çš„é—®é¢˜"
        )

    def _normalize_issues(self, issues: List[Union[Dict, str]]) -> List[Dict]:
        normalized = []
        for issue in issues:
            if isinstance(issue, dict):
                normalized.append(issue)
            elif isinstance(issue, str):
                parsed = self._parse_issue_string(issue)
                normalized.append(parsed)
            else:
                normalized.append({
                    "type": "unknown",
                    "message": str(issue),
                    "rule_id": "UNKNOWN"
                })
        return normalized

    def _parse_issue_string(self, issue_str: str) -> Dict[str, Any]:
        pattern1 = r'^([^:]+):(\d+):(\d+):\s*([A-Z]\d+)\s+(.+)$'
        match = re.match(pattern1, issue_str)
        if match:
            return {
                "file": match.group(1),
                "line": int(match.group(2)),
                "column": int(match.group(3)),
                "rule_id": match.group(4),
                "message": match.group(5),
                "severity": self._get_severity_from_code(match.group(4))
            }

        pattern2 = r'^([^:]+):(\d+):\s*([A-Z]\d+)\s+(.+)$'
        match = re.match(pattern2, issue_str)
        if match:
            return {
                "file": match.group(1),
                "line": int(match.group(2)),
                "rule_id": match.group(3),
                "message": match.group(4),
                "severity": self._get_severity_from_code(match.group(3))
            }

        return {
            "type": "unknown",
            "message": issue_str,
            "rule_id": "UNKNOWN",
            "severity": "MEDIUM"
        }

    def _get_severity_from_code(self, code: str) -> str:
        if code.startswith('E'):
            return 'HIGH'
        elif code.startswith('W'):
            return 'MEDIUM'
        return 'LOW'

    def _apply_common_fixes(self, content: str, issues: List[Dict]) -> tuple:
        fixed_content = content
        fix_count = 0

        if any(issue.get("rule_id") == "W291" for issue in issues):
            new_content = re.sub(r'[ \t]+$', '', fixed_content, flags=re.MULTILINE)
            if new_content != fixed_content:
                fixed_content = new_content
                fix_count += 1

        if any(issue.get("rule_id") == "W391" for issue in issues):
            new_content = fixed_content.rstrip() + '\n'
            if new_content != fixed_content:
                fixed_content = new_content
                fix_count += 1

        return fixed_content, fix_count

    # =========================================================
    #  LLM ä¿®å¤
    # =========================================================
    def apply_llm_fixes(self, file: Dict[str, Any], issues: List[Union[Dict, str]],
                        user_request: str = "") -> FixResult:
        filename = file.get("file", "")
        content = file.get("content", "")

        result = FixResult(
            file=filename,
            language=self.language.value,
            original_content=content,
            fixed_content=content,
            fixed_count=0,
            method="llm",
            success=False
        )

        if not self.llm_client:
            result.error_message = "LLMå®¢æˆ·ç«¯æœªé…ç½®"
            print(f"[PythonFixer] LLMå®¢æˆ·ç«¯æœªé…ç½®")
            return result

        print(f"[PythonFixer] å¼€å§‹LLMä¿®å¤: {filename}")
        print(f"[PythonFixer] é—®é¢˜æ•°: {len(issues)}")

        try:
            normalized_issues = self._normalize_issues(issues)

            system_prompt = self._build_system_prompt()
            user_prompt = self._build_user_prompt(
                filename=filename,
                original_content=content,
                issues=normalized_issues,
                user_request=user_request,
                force_code_block_only=self.prompt_conf.get("force_code_block_only", True)
            )

            print(f"[PythonFixer] è°ƒç”¨LLM API...")

            if hasattr(self.llm_client, 'chat') and callable(self.llm_client.chat):
                response = self.llm_client.chat(
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.3,
                    max_tokens=4000
                )
            else:
                result.error_message = "ä¸æ”¯æŒçš„LLMå®¢æˆ·ç«¯ç±»å‹"
                return result

            print(f"[PythonFixer] LLMå“åº”é•¿åº¦: {len(response)} å­—ç¬¦")

            fixed_code = self._extract_code_from_response(response, filename)

            if fixed_code and fixed_code != content:
                result.fixed_content = fixed_code
                result.fixed_count = max(1, len(normalized_issues))
                result.success = True
                print(f"[PythonFixer] LLMä¿®å¤æˆåŠŸ")
            else:
                result.error_message = "LLMæœªè¿”å›æœ‰æ•ˆçš„ä¿®å¤ä»£ç "
                print(f"[PythonFixer] LLMä¿®å¤å¤±è´¥: æœªè¿”å›æœ‰æ•ˆä»£ç ")

        except Exception as e:
            result.error_message = f"LLMè°ƒç”¨å¤±è´¥: {str(e)}"
            print(f"[PythonFixer] LLMè°ƒç”¨å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()

        return result

    def _build_system_prompt(self) -> str:
        lang = self.prompt_conf.get("language", "zh")
        style = self.prompt_conf.get("style", "concise")
        return (
            f"ä½ æ˜¯ä¸“ä¸šçš„ Python ä»£ç ä¿®å¤åŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼éµå®ˆï¼š\n"
            f"1) ä»…è¾“å‡ºå®Œæ•´çš„ä»£ç ï¼Œä¸è¦è¾“å‡ºè§£é‡Šã€‚\n"
            f"2) è¾“å‡ºæ ¼å¼å¿…é¡»ä¸ºä¸€ä¸ªå¸¦æ–‡ä»¶åçš„ python ä»£ç å—ï¼š```python <æ–‡ä»¶å>.py\\n<å®Œæ•´ä»£ç >```\n"
            f"3) ä¸è¦è¾“å‡º diffã€ä¸è¦è¾“å‡ºå¤šä½™æ–‡æœ¬æˆ–å¤šä¸ªä»£ç å—ã€‚\n"
            f"4) å¦‚æœæ— æ³•ä¿®å¤ï¼Œè¯·ä¹Ÿè¾“å‡ºåŸæ ·çš„å®Œæ•´æ–‡ä»¶ä»£ç å—ã€‚\n"
            f"è¯­è¨€ï¼š{lang}ï¼›é£æ ¼ï¼š{style}ã€‚\n"
        )

    def _build_user_prompt(
            self,
            filename: str,
            original_content: str,
            issues: List[Dict[str, Any]],
            user_request: str,
            force_code_block_only: bool
    ) -> str:
        lang_ext = "python"

        debugbench_mode = False
        reference_code = ""
        if user_request and "[DEBUGBENCH]" in user_request:
            debugbench_mode = True
            start_tag = "ã€å‚è€ƒæ­£ç¡®å®ç°ï¼ˆground truthï¼‰ã€‘"
            end_tag = "ã€å‚è€ƒå®ç°ç»“æŸã€‘"
            start_idx = user_request.find(start_tag)
            end_idx = user_request.find(end_tag)
            if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                reference_code = user_request[start_idx + len(start_tag):end_idx].strip()

        # ğŸ”¥ è£å‰ªè¿‡é•¿çš„ä»£ç ï¼Œé˜²æ­¢ OOM
        MAX_CHARS = 6000
        if len(original_content) > MAX_CHARS:
            truncated_content = original_content[:MAX_CHARS] + "\n\n# ... (ä»£ç è¿‡é•¿ï¼Œä»…æ˜¾ç¤ºå‰ 6000 å­—ç¬¦) ..."
        else:
            truncated_content = original_content

        # DebugBench é€»è¾‘ä¿æŒä¸å˜
        if debugbench_mode and reference_code:
            strict_hint = (
                "ã€é‡è¦ã€‘åªè¾“å‡ºä¸€ä¸ªå¸¦æ–‡ä»¶åçš„ python ä»£ç å—ï¼Œä¸è¦ä»»ä½•è¯´æ˜æ–‡å­—ã€ä¸è¦ diffã€‚"
                if force_code_block_only else
                "å¦‚æœå¯èƒ½ï¼Œåªè¾“å‡ºä¸€ä¸ªå¸¦æ–‡ä»¶åçš„ python ä»£ç å—ï¼›ä¸è¦è¾“å‡º diff æˆ–è§£é‡Šã€‚"
            )
            logic_issues = self._analyze_logic_diff_v2(truncated_content, reference_code)
            logic_report = "\n".join(f"- [{it.get('type', 'LOGIC')}] {it.get('message', '')}" for it in logic_issues)
            return (
                "ä½ æ­£åœ¨è¿›è¡Œä¸€ä¸ªåä¸º DebugBench çš„è‡ªåŠ¨ Python ä»£ç ä¿®å¤ä»»åŠ¡ã€‚\n"
                f"ã€é€»è¾‘å·®å¼‚æŠ¥å‘Šã€‘\n{logic_report}\n\n"
                f"ã€åŸå§‹ä»£ç ã€‘\n{truncated_content}\n\n"
                f"{strict_hint}\n"
                f"è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š\n```python\n<å®Œæ•´ä»£ç >\n```\n"
            )

        # === å¸¸è§„ä¿®å¤ Prompt æ„å»º ===
        issue_lines = []
        for it in issues:
            issue_lines.append(
                f"- [{it.get('rule_id', '')}] è¡Œ {it.get('line', '?')}: {it.get('message', '')}"
            )
        issue_text = "\n".join(issue_lines) if issue_lines else "æ— ç»“æ„åŒ–ç¼ºé™·æ¡ç›®ï¼ˆå¯èƒ½æ˜¯å¤–éƒ¨å·¥å…·æˆ–åŠ¨æ€é—®é¢˜ï¼‰ã€‚"

        strict_hint = (
            "ã€é‡è¦ã€‘åªè¾“å‡ºä¸€ä¸ªå¸¦æ–‡ä»¶åçš„ python ä»£ç å—ã€‚ä¸è¦è¾“å‡º diffã€ä¸è¦è¾“å‡ºæ–‡ä»¶åã€ä¸è¦è¾“å‡ºè§£é‡Šæ–‡å­—ã€‚"
            "ã€æ³¨æ„ã€‘ç¡®ä¿ä¿®æ”¹åçš„ä»£ç ä¿æŒåŸæœ‰çš„å‡½æ•°ç­¾åå’Œç±»ç»“æ„ï¼Œä¸è¦åˆ é™¤ç°æœ‰çš„åŠŸèƒ½ï¼Œåªä¿®å¤æŠ¥é”™çš„é—®é¢˜ã€‚"  # ğŸ”¥ åŠ å¼ºçº¦æŸ
            if force_code_block_only else
            "è¯·ç›´æ¥è¾“å‡ºä¿®å¤åçš„å®Œæ•´ä»£ç å—ã€‚"
        )

        extra = ""
        if user_request and "[DEBUGBENCH]" not in user_request:
            extra = f"\nã€ç”¨æˆ·è¡¥å……éœ€æ±‚ã€‘\n{user_request}\n"

        return (
            f"è¯·ä¿®å¤ä¸‹è¿°æ–‡ä»¶ä¸­çš„é—®é¢˜ï¼Œå¹¶è¿”å›ä¿®å¤åçš„å®Œæ•´æºä»£ç ã€‚\n\n"
            f"ã€ç›®æ ‡æ–‡ä»¶ã€‘{filename}\n"
            f"ã€æ£€æµ‹åˆ°çš„é—®é¢˜ã€‘\n{issue_text}\n"
            f"{extra}\n"
            f"ã€åŸå§‹ä»£ç å¼€å§‹ã€‘\n{truncated_content}\nã€åŸå§‹ä»£ç ç»“æŸã€‘\n\n"
            f"{strict_hint}\n"
            f"è¯·ç›´æ¥è¾“å‡º Python ä»£ç å—ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n"
            f"```python\n"
            f"<å®Œæ•´ä»£ç >\n"
            f"```\n"
        )

    def _extract_code_from_response(self, response: str, expected_filename: str) -> str:
        # æ¸…ç†é¦–å°¾ç©ºç™½
        response = response.strip()

        # 1. å°è¯•åŒ¹é…æ ‡å‡† ```python ... ``` (å¿½ç•¥æ–‡ä»¶å)
        pattern_std = r"```(?:python|py).*?\n(.*?)```"
        matches = re.findall(pattern_std, response, re.DOTALL | re.IGNORECASE)
        if matches:
            # é€‰æœ€é•¿çš„ä¸€ä¸ªå—ï¼Œé˜²æ­¢é€‰åˆ°çŸ­å°çš„ç¤ºä¾‹ä»£ç 
            return max(matches, key=len).strip()

        # 2. å°è¯•åŒ¹é…é€šç”¨ ``` ... ```
        pattern_generic = r"```.*?\n(.*?)```"
        matches = re.findall(pattern_generic, response, re.DOTALL)
        if matches:
            return max(matches, key=len).strip()

        # 3. ğŸ”¥ æš´åŠ›æå–ï¼šå¦‚æœ LLM æ²¡å†™ Markdown æ ‡è®°ï¼Œç›´æ¥æŒ‰è¡Œè¿‡æ»¤
        # è¿™ç§æƒ…å†µåœ¨æœ¬åœ°å°æ¨¡å‹ä¸­éå¸¸å¸¸è§
        lines = response.split('\n')
        code_lines = []
        is_code_started = False

        for line in lines:
            stripped = line.strip()
            # å¦‚æœé‡åˆ° import, class, def, fromï¼Œè®¤ä¸ºä»£ç å¼€å§‹äº†
            if (stripped.startswith('import ') or
                    stripped.startswith('from ') or
                    stripped.startswith('def ') or
                    stripped.startswith('class ') or
                    stripped.startswith('@')):
                is_code_started = True

            # å¦‚æœå·²ç»å¼€å§‹ï¼Œæˆ–è€…æ˜¯ç©ºè¡Œï¼ˆä¿ç•™ç©ºè¡Œæ ¼å¼ï¼‰ï¼Œæˆ–è€…æ˜¯æ³¨é‡Š
            if is_code_started:
                # ç®€å•è¿‡æ»¤ä¸€ä¸‹ç»“å°¾å¸¸è§çš„ "Explanation:" ä¹‹ç±»çš„åºŸè¯
                if stripped.lower().startswith("explanation:") or stripped.lower().startswith("note:"):
                    break
                code_lines.append(line)

        # åªæœ‰å½“æå–åˆ°äº†æœ‰æ•ˆçš„ä»£ç è¡Œï¼ˆå¤§äº3è¡Œï¼‰æ‰è¿”å›
        if len(code_lines) > 3:
            return "\n".join(code_lines).strip()

        # 4. ç»æœ›å…œåº•ï¼šå¦‚æœæ•´ä¸ªå›å¤åŒ…å«å…³é”®å­—ï¼Œç›´æ¥å½“åšä»£ç è¿”å›
        # å®å¯æŠ¥é”™ä¹Ÿä¸è¦è¿”å›ç©ºï¼Œå› ä¸ºè¿”å›ç©ºä¼šå¯¼è‡´ Fixer è®¤ä¸ºå¤±è´¥è€Œå›æ»š
        if "def " in response or "import " in response:
            return response

        return ""
    # =========================================================
    #  Python ä»£ç å½’ä¸€åŒ–ï¼ˆä¾› runner ä½¿ç”¨ï¼Œå¯é€‰ï¼‰
    # =========================================================
    @staticmethod
    def normalize_python(code: str) -> str:
        """
        å¯¹ Python åšç®€å•å½’ä¸€åŒ–ï¼š
        - å»æ‰è¡Œå°¾ç©ºç™½
        - å»æ‰å¤šä½™ç©ºè¡Œ

        æ³¨æ„ï¼šDebugBench çš„è¯„ä¼°ä½¿ç”¨çš„æ˜¯ runner å†…çš„ normalize_pythonï¼›
        è¿™é‡Œæä¾›çš„æ˜¯å¤‡ç”¨å®ç°ï¼ˆä¿æŒä¸ CppFixer.normalize_cpp åŒæ ·çš„æ¥å£é£æ ¼ï¼‰ã€‚
        """
        lines = code.splitlines()
        cleaned = [re.sub(r'[ \t]+$', '', l) for l in lines]
        text = "\n".join(cleaned)
        text = text.strip() + "\n"
        return text